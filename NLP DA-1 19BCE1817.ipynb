{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59dec136",
   "metadata": {},
   "source": [
    "# CSE4022 Natural Language Processing\n",
    "## Digital Assignment-1\n",
    "### Theninpan.R\n",
    "### 19BCE1817\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219bc495",
   "metadata": {},
   "source": [
    "#### 1.\tUtilize Python NLTK (Natural Language Tool Kit) Platform and do the following. Install relevant Packages and Libraries\n",
    "\n",
    "•\tExplore Brown Corpus and find the size, tokens, categories,\n",
    "\n",
    "•\tFind the size of word tokens?\n",
    "\n",
    "•\tFind the size of word types?\n",
    "\n",
    "•\tFind the size of category “government”\n",
    "\n",
    "•\tList the most frequent tokens\n",
    "\n",
    "•\tCount the number of sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6a158f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.corpus import indian\n",
    "from nltk.corpus import names\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ab0d55c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca01',\n",
       " 'ca02',\n",
       " 'ca03',\n",
       " 'ca04',\n",
       " 'ca05',\n",
       " 'ca06',\n",
       " 'ca07',\n",
       " 'ca08',\n",
       " 'ca09',\n",
       " 'ca10',\n",
       " 'ca11',\n",
       " 'ca12',\n",
       " 'ca13',\n",
       " 'ca14',\n",
       " 'ca15']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting to know the files in Brown corpus\n",
    "brown.fileids()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "58f3548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of brown corpus= 1161192\n"
     ]
    }
   ],
   "source": [
    "#Size of Brown corpus\n",
    "print(\"Size of brown corpus=\",len(brown.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7076a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]\n",
      "['Austin', ',', 'Texas', '--', 'Committee', 'approval', ...]\n",
      "['Assembly', 'session', 'brought', 'much', 'good', ...]\n",
      "['If', 'the', 'content', 'of', 'faith', 'is', 'to', ...]\n"
     ]
    }
   ],
   "source": [
    "# Printing some words from Brown corpus files\n",
    "print(brown.words('ca01'))\n",
    "print(brown.words('ca02'))\n",
    "print(brown.words('cb01'))\n",
    "print(brown.words('cd02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ebae2cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "# Printing different categories in Brown corpus\n",
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ee738c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word tokens of file ca01 =  2242\n",
      "Size of word tokens of file ca02 =  2277\n",
      "Size of word tokens of file ca03 =  2275\n",
      "Size of word tokens of file ca04 =  2217\n",
      "Size of word tokens of file ca05 =  2244\n",
      "Size of word tokens of file ca06 =  2263\n",
      "Size of word tokens of file ca07 =  2270\n",
      "Size of word tokens of file ca08 =  2187\n",
      "Size of word tokens of file ca09 =  2234\n",
      "Size of word tokens of file ca10 =  2282\n",
      "Size of word tokens of file ca11 =  2259\n",
      "Size of word tokens of file ca12 =  2338\n",
      "Size of word tokens of file ca13 =  2241\n",
      "Size of word tokens of file ca14 =  2329\n",
      "Size of word tokens of file ca15 =  2314\n",
      "\n",
      "\n",
      "Size of adventure category =  69342\n",
      "Size of belles_lettres category =  173096\n",
      "Size of editorial category =  61604\n",
      "Size of fiction category =  68488\n",
      "Size of government category =  70117\n",
      "Size of hobbies category =  82345\n",
      "Size of humor category =  21695\n",
      "Size of learned category =  181888\n",
      "Size of lore category =  110299\n",
      "Size of mystery category =  57169\n",
      "Size of news category =  100554\n",
      "Size of religion category =  39399\n",
      "Size of reviews category =  40704\n",
      "Size of romance category =  70022\n",
      "Size of science_fiction category =  14470\n"
     ]
    }
   ],
   "source": [
    "# Size of word tokens in first 15 files\n",
    "for c in brown.fileids()[:15]:\n",
    "    print(\"Size of word tokens of file \"+c+' = ',len(brown.words(c)))\n",
    "print(\"\\n\")\n",
    "# Size of word tokens in different categories\n",
    "for w in brown.categories():\n",
    "    catg=brown.words(categories=w)\n",
    "    print(\"Size of \"+w+\" category = \",len(catg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c6d7b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word types in ca01 =  848\n",
      "Number of word types in ca02 =  908\n",
      "Number of word types in ca03 =  808\n",
      "Number of word types in ca04 =  895\n",
      "Number of word types in ca05 =  756\n",
      "Number of word types in ca06 =  835\n",
      "Number of word types in ca07 =  894\n",
      "Number of word types in ca08 =  826\n",
      "Number of word types in ca09 =  891\n",
      "Number of word types in ca10 =  871\n",
      "Number of word types in ca11 =  912\n",
      "Number of word types in ca12 =  828\n",
      "Number of word types in ca13 =  886\n",
      "Number of word types in ca14 =  945\n",
      "Number of word types in ca15 =  906\n",
      "\n",
      "\n",
      "Number of word types in adventure =  8874\n",
      "Number of word types in belles_lettres =  18421\n",
      "Number of word types in editorial =  9890\n",
      "Number of word types in fiction =  9302\n",
      "Number of word types in government =  8181\n",
      "Number of word types in hobbies =  11935\n",
      "Number of word types in humor =  5017\n",
      "Number of word types in learned =  16859\n",
      "Number of word types in lore =  14503\n",
      "Number of word types in mystery =  6982\n",
      "Number of word types in news =  14394\n",
      "Number of word types in religion =  6373\n",
      "Number of word types in reviews =  8626\n",
      "Number of word types in romance =  8452\n",
      "Number of word types in science_fiction =  3233\n"
     ]
    }
   ],
   "source": [
    "# Size of word types\n",
    "for c in brown.fileids()[:15]:\n",
    "    fil = brown.words(c)\n",
    "    print(\"Number of word types in \"+c+\" = \",len(set(fil)))\n",
    "print(\"\\n\")\n",
    "\n",
    "for w in brown.categories():\n",
    "    fil = brown.words(categories=w)\n",
    "    print(\"Number of word types in \"+w+\" = \",len(set(fil))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1c6faf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Government category =  70117\n"
     ]
    }
   ],
   "source": [
    "# Size of category government\n",
    "gov=brown.words(categories='government')\n",
    "print(\"Size of Government category = \",len(gov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "627c4d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent tokens in ca01 =  [('the', 127)]\n",
      "Most frequent tokens in ca02 =  [(',', 121)]\n",
      "Most frequent tokens in ca03 =  [('the', 128)]\n",
      "Most frequent tokens in ca04 =  [('the', 141)]\n",
      "Most frequent tokens in ca05 =  [('the', 155)]\n",
      "Most frequent tokens in ca06 =  [('the', 139)]\n",
      "Most frequent tokens in ca07 =  [('the', 137)]\n",
      "Most frequent tokens in ca08 =  [('the', 169)]\n",
      "Most frequent tokens in ca09 =  [('the', 146)]\n",
      "Most frequent tokens in ca10 =  [('the', 117)]\n",
      "Most frequent tokens in ca11 =  [('the', 138)]\n",
      "Most frequent tokens in ca12 =  [(',', 119)]\n",
      "Most frequent tokens in ca13 =  [('the', 142)]\n",
      "Most frequent tokens in ca14 =  [('the', 156)]\n",
      "Most frequent tokens in ca15 =  [(',', 144)]\n"
     ]
    }
   ],
   "source": [
    "# Most frequent tokens\n",
    "for c in brown.fileids()[:15]:\n",
    "    fdist = FreqDist(brown.words(c)) \n",
    "    top = fdist.most_common(1)\n",
    "    print(\"Most frequent tokens in \"+c+' = ',top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e49506eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in ca01 =  98\n",
      "Number of sentences in ca02 =  98\n",
      "Number of sentences in ca03 =  112\n",
      "Number of sentences in ca04 =  88\n",
      "Number of sentences in ca05 =  84\n",
      "Number of sentences in ca06 =  99\n",
      "Number of sentences in ca07 =  120\n",
      "Number of sentences in ca08 =  101\n",
      "Number of sentences in ca09 =  113\n",
      "Number of sentences in ca10 =  106\n",
      "Number of sentences in ca11 =  100\n",
      "Number of sentences in ca12 =  104\n",
      "Number of sentences in ca13 =  108\n",
      "Number of sentences in ca14 =  133\n",
      "Number of sentences in ca15 =  110\n"
     ]
    }
   ],
   "source": [
    "# Number of sentences\n",
    "for c in brown.fileids()[:15]:\n",
    "    num_sents = len(brown.sents(c))\n",
    "    print(\"Number of sentences in \"+c+' = ',num_sents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f36ff",
   "metadata": {},
   "source": [
    "#### 2.\tExplore the corpora available in NLTK                                          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4451d",
   "metadata": {},
   "source": [
    "##### Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4a73297f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring Gutenberg corpora\n",
    "# Getting to know the files in Gutenberg corpus\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f42efd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Gutenberg corpus= 2621613\n"
     ]
    }
   ],
   "source": [
    "#Size of Gutenberg corpus\n",
    "print(\"Size of Gutenberg corpus=\",len(gutenberg.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8158b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word tokens of file austen-emma.txt =  192427\n",
      "Number of word types in austen-emma.txt =  7811\n",
      "Most frequent tokens in austen-emma.txt =  [(',', 11454)]\n",
      "Number of sentences in austen-emma.txt =  7717\n",
      "\n",
      "\n",
      "Size of word tokens of file austen-persuasion.txt =  98171\n",
      "Number of word types in austen-persuasion.txt =  6132\n",
      "Most frequent tokens in austen-persuasion.txt =  [(',', 6750)]\n",
      "Number of sentences in austen-persuasion.txt =  3747\n",
      "\n",
      "\n",
      "Size of word tokens of file austen-sense.txt =  141576\n",
      "Number of word types in austen-sense.txt =  6833\n",
      "Most frequent tokens in austen-sense.txt =  [(',', 9397)]\n",
      "Number of sentences in austen-sense.txt =  4999\n",
      "\n",
      "\n",
      "Size of word tokens of file bible-kjv.txt =  1010654\n",
      "Number of word types in bible-kjv.txt =  13769\n",
      "Most frequent tokens in bible-kjv.txt =  [(',', 70509)]\n",
      "Number of sentences in bible-kjv.txt =  30103\n",
      "\n",
      "\n",
      "Size of word tokens of file blake-poems.txt =  8354\n",
      "Number of word types in blake-poems.txt =  1820\n",
      "Most frequent tokens in blake-poems.txt =  [(',', 680)]\n",
      "Number of sentences in blake-poems.txt =  438\n",
      "\n",
      "\n",
      "Size of word tokens of file bryant-stories.txt =  55563\n",
      "Number of word types in bryant-stories.txt =  4420\n",
      "Most frequent tokens in bryant-stories.txt =  [(',', 3481)]\n",
      "Number of sentences in bryant-stories.txt =  2863\n",
      "\n",
      "\n",
      "Size of word tokens of file burgess-busterbrown.txt =  18963\n",
      "Number of word types in burgess-busterbrown.txt =  1764\n",
      "Most frequent tokens in burgess-busterbrown.txt =  [('.', 823)]\n",
      "Number of sentences in burgess-busterbrown.txt =  1054\n",
      "\n",
      "\n",
      "Size of word tokens of file carroll-alice.txt =  34110\n",
      "Number of word types in carroll-alice.txt =  3016\n",
      "Most frequent tokens in carroll-alice.txt =  [(',', 1993)]\n",
      "Number of sentences in carroll-alice.txt =  1703\n",
      "\n",
      "\n",
      "Size of word tokens of file chesterton-ball.txt =  96996\n",
      "Number of word types in chesterton-ball.txt =  8947\n",
      "Most frequent tokens in chesterton-ball.txt =  [(',', 4547)]\n",
      "Number of sentences in chesterton-ball.txt =  4779\n",
      "\n",
      "\n",
      "Size of word tokens of file chesterton-brown.txt =  86063\n",
      "Number of word types in chesterton-brown.txt =  8299\n",
      "Most frequent tokens in chesterton-brown.txt =  [('the', 4321)]\n",
      "Number of sentences in chesterton-brown.txt =  3806\n",
      "\n",
      "\n",
      "Size of word tokens of file chesterton-thursday.txt =  69213\n",
      "Number of word types in chesterton-thursday.txt =  6807\n",
      "Most frequent tokens in chesterton-thursday.txt =  [(',', 3488)]\n",
      "Number of sentences in chesterton-thursday.txt =  3728\n",
      "\n",
      "\n",
      "Size of word tokens of file edgeworth-parents.txt =  210663\n",
      "Number of word types in edgeworth-parents.txt =  9593\n",
      "Most frequent tokens in edgeworth-parents.txt =  [(',', 15219)]\n",
      "Number of sentences in edgeworth-parents.txt =  10230\n",
      "\n",
      "\n",
      "Size of word tokens of file melville-moby_dick.txt =  260819\n",
      "Number of word types in melville-moby_dick.txt =  19317\n",
      "Most frequent tokens in melville-moby_dick.txt =  [(',', 18713)]\n",
      "Number of sentences in melville-moby_dick.txt =  10059\n",
      "\n",
      "\n",
      "Size of word tokens of file milton-paradise.txt =  96825\n",
      "Number of word types in milton-paradise.txt =  10751\n",
      "Most frequent tokens in milton-paradise.txt =  [(',', 10198)]\n",
      "Number of sentences in milton-paradise.txt =  1851\n",
      "\n",
      "\n",
      "Size of word tokens of file shakespeare-caesar.txt =  25833\n",
      "Number of word types in shakespeare-caesar.txt =  3560\n",
      "Most frequent tokens in shakespeare-caesar.txt =  [(',', 2204)]\n",
      "Number of sentences in shakespeare-caesar.txt =  2163\n",
      "\n",
      "\n",
      "Size of word tokens of file shakespeare-hamlet.txt =  37360\n",
      "Number of word types in shakespeare-hamlet.txt =  5447\n",
      "Most frequent tokens in shakespeare-hamlet.txt =  [(',', 2892)]\n",
      "Number of sentences in shakespeare-hamlet.txt =  3106\n",
      "\n",
      "\n",
      "Size of word tokens of file shakespeare-macbeth.txt =  23140\n",
      "Number of word types in shakespeare-macbeth.txt =  4017\n",
      "Most frequent tokens in shakespeare-macbeth.txt =  [(',', 1962)]\n",
      "Number of sentences in shakespeare-macbeth.txt =  1907\n",
      "\n",
      "\n",
      "Size of word tokens of file whitman-leaves.txt =  154883\n",
      "Number of word types in whitman-leaves.txt =  14329\n",
      "Most frequent tokens in whitman-leaves.txt =  [(',', 17713)]\n",
      "Number of sentences in whitman-leaves.txt =  4250\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Size of word tokens, number of sentences and frequent words\n",
    "for c in gutenberg.fileids():\n",
    "    fil = gutenberg.words(c)\n",
    "    fdist = FreqDist(gutenberg.words(c)) \n",
    "    top = fdist.most_common(1)\n",
    "    num_sents = len(gutenberg.sents(c))\n",
    "    print(\"Size of word tokens of file \"+c+' = ',len(fil))\n",
    "    print(\"Number of word types in \"+c+\" = \",len(set(fil)))\n",
    "    print(\"Most frequent tokens in \"+c+' = ',top)\n",
    "    print(\"Number of sentences in \"+c+' = ',num_sents)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62cd595",
   "metadata": {},
   "source": [
    "##### Indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5bcf8c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bangla.pos', 'hindi.pos', 'marathi.pos', 'telugu.pos']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring Indian corpora\n",
    "# Getting to know the files in Indian corpus\n",
    "indian.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bff502a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Gutenberg corpus= 48754\n"
     ]
    }
   ],
   "source": [
    "#Size of indian corpus\n",
    "print(\"Size of Gutenberg corpus=\",len(indian.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1ab77745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word tokens of file bangla.pos =  10281\n",
      "Number of word types in bangla.pos =  3637\n",
      "Most frequent tokens in bangla.pos =  [('৷', 840)]\n",
      "Number of sentences in bangla.pos =  896\n",
      "\n",
      "\n",
      "Size of word tokens of file hindi.pos =  9408\n",
      "Number of word types in hindi.pos =  2186\n",
      "Most frequent tokens in hindi.pos =  [('।', 493)]\n",
      "Number of sentences in hindi.pos =  540\n",
      "\n",
      "\n",
      "Size of word tokens of file marathi.pos =  19066\n",
      "Number of word types in marathi.pos =  6518\n",
      "Most frequent tokens in marathi.pos =  [('.', 1180)]\n",
      "Number of sentences in marathi.pos =  1197\n",
      "\n",
      "\n",
      "Size of word tokens of file telugu.pos =  9999\n",
      "Number of word types in telugu.pos =  4209\n",
      "Most frequent tokens in telugu.pos =  [('.', 994)]\n",
      "Number of sentences in telugu.pos =  994\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Size of word tokens, number of sentences and frequent words\n",
    "for c in indian.fileids():\n",
    "    fil = indian.words(c)\n",
    "    fdist = FreqDist(indian.words(c)) \n",
    "    top = fdist.most_common(1)\n",
    "    num_sents = len(indian.sents(c))\n",
    "    print(\"Size of word tokens of file \"+c+' = ',len(fil))\n",
    "    print(\"Number of word types in \"+c+\" = \",len(set(fil)))\n",
    "    print(\"Most frequent tokens in \"+c+' = ',top)\n",
    "    print(\"Number of sentences in \"+c+' = ',num_sents)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
